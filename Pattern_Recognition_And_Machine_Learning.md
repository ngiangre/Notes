# Chapter 1 Introduction to searching forc patterns in data

- Generalization: the ability of a model to correctly categorize examples that different from the training/learning phase
- Density estimation: determining the distribution of the data within the input space.
- Model coefficient's magnitudes may correspond with overrfitting - a general property of maximum likelihood
- Regularization of neural networks uses weight decay
- Elementary rules of probability: the sum and product rules (Bayes theorem is the product rule divided by the sum rule essentially)
- When deciding what to do for a patient xi within the infered P(x,t), we can either decide based on the posterior P(t|xi), based on a decision region with the fewest misclassifications, minimizing the expected loss of a specified criteria, not deciding based on a posterior threshold value, or jointly modeling the inference-decision process (discrimination) 
- Information theory: how much information is received when we observe a specific value for this variable. The amount of information can be viewed as the ‘degree of surprise’ on learning the value of x.
- the mutual information can be thought of as the reduction in the uncertainty about x by virtue of being told the value of y
 
